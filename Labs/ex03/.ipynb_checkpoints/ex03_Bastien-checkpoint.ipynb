{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# Useful starting lines\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Least squares and linear basis functions models\n",
    "## Least squares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def compute_mse(y, tx, w):\n",
    "   \n",
    "    y = y.reshape(-1, 1)\n",
    "    w = w.reshape(-1, 1)\n",
    "\n",
    "    e = y - tx.dot(w)\n",
    "\n",
    "    L = 1/(2*y.shape[0]) * np.square(e).sum()\n",
    "    #print(L)\n",
    "    \n",
    "    return L\n",
    "\n",
    "def compute_rmse(y, tx, w):\n",
    "    return np.sqrt(2*compute_mse(y, tx, w))\n",
    "\n",
    "\n",
    "def least_squares(y, tx):\n",
    "    \"\"\"calculate the least squares solution.\"\"\"\n",
    "    # ***************************************************\n",
    "    # INSERT YOUR CODE HERE\n",
    "    # least squares: TODO\n",
    "    # returns mse, and optimal weights\n",
    "    # ***************************************************\n",
    "    y = y.reshape(-1, 1)\n",
    "    \n",
    "    txt = np.transpose(tx)\n",
    "    XTX = txt.dot(tx)\n",
    "    \n",
    "    w = np.linalg.inv(XTX).dot(txt).dot(y)\n",
    "    \n",
    "    e = y - tx.dot(w)\n",
    "    L = 1/(2*y.shape[0]) * np.square(e).sum()\n",
    "    \n",
    "    return w,L\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the data\n",
    "Here we will reuse the dataset `height_weight_genders.csv` from previous exercise section to check the correctness of your implementation. Please compare it with your previous result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'datetime' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-34b43ffd5932>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m \u001b[0mtest_your_least_squares\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-2-34b43ffd5932>\u001b[0m in \u001b[0;36mtest_your_least_squares\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mgradDescentExecTime\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;36m0.017\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m     \u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mL\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mleast_squares\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mend_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'datetime' is not defined"
     ]
    }
   ],
   "source": [
    "from helpers import *\n",
    "def test_your_least_squares():\n",
    "    height, weight, gender = load_data_from_ex02(sub_sample=False, add_outlier=False)\n",
    "    x, mean_x, std_x = standardize(height)\n",
    "    y, tx = build_model_data(x, weight)\n",
    "    # ***************************************************\n",
    "    # INSERT YOUR CODE HERE\n",
    "    # least square or grid search: TODO\n",
    "    # this code should compare the optimal weights obtained \n",
    "    # by least squares vs. grid search\n",
    "    # ***************************************************\n",
    "    gradDescentLoss = 15.385887868829402 \n",
    "    gradDescentW = [73.293922, 13.47971243]\n",
    "    gradDescentExecTime =0.017\n",
    "    \n",
    "    start_time = datetime.datetime.now()\n",
    "    w, L = least_squares(y, tx)\n",
    "    end_time = datetime.datetime.now()\n",
    "\n",
    "    exection_time = (end_time - start_time).total_seconds()\n",
    "    \n",
    "    # Print result    \n",
    "    print (\"gradient descend w : {}\".format(gradDescentW))\n",
    "    print (\"least squares w : {}\".format(w))\n",
    "    print (\"delta_w : {}\\n\".format(w-gradDescentW))\n",
    "    \n",
    "    print (\"gradient descend Loss : {}\".format(gradDescentLoss))\n",
    "    print (\"least square Loss : {}\".format(L))\n",
    "    print (\"delta_loss : {}\\n\".format(L-gradDescentLoss))\n",
    "    \n",
    "    print (\"gradient descend exec time : {}\".format(gradDescentExecTime))\n",
    "    print (\"least square exec time : {}\".format(exection_time))\n",
    "    print (\"delta exec time : {}\\n\".format(exection_time-gradDescentExecTime))\n",
    "    \n",
    "    return 0\n",
    "    \n",
    "\n",
    "test_your_least_squares()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Least squares with a linear basis function model\n",
    "Start from this section, we will use the dataset `dataEx3.csv`.\n",
    "\n",
    "### Implement polynomial basis functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of x (50,)\n",
      "shape of y (50,)\n"
     ]
    }
   ],
   "source": [
    "# load dataset\n",
    "x, y = load_data()\n",
    "print(\"shape of x {}\".format(x.shape))\n",
    "print(\"shape of y {}\".format(y.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def build_poly(x, degree):\n",
    "    \"\"\"polynomial basis functions for input data x, for j=0 up to j=degree.\"\"\"\n",
    "    # ***************************************************\n",
    "    # INSERT YOUR CODE HERE\n",
    "    # polynomial basis function: TODO\n",
    "    # this function should return the matrix formed\n",
    "    # by applying the polynomial basis to the input data\n",
    "    # ***************************************************\n",
    "    x = x.reshape(-1)    \n",
    "    phi = np.zeros((x.shape[0], degree+1))\n",
    "            \n",
    "    for n in range(degree+1):\n",
    "        phi[:, n] = phi[:, n]+np.power(x, n)\n",
    "       \n",
    "    return phi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us play with polynomial regression. Note that we will use your implemented function `compute_mse`. Please copy and paste your implementation from exercise02."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 1th experiment, degree=1, rmse=0.47187607963421874\n",
      "Processing 2th experiment, degree=3, rmse=0.25858277667737484\n",
      "Processing 3th experiment, degree=7, rmse=0.24965870360907205\n",
      "Processing 4th experiment, degree=12, rmse=1.3106193798124992\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/joeltheytaz/anaconda3/lib/python3.5/site-packages/matplotlib/tight_layout.py:222: UserWarning: tight_layout : falling back to Agg renderer\n",
      "  warnings.warn(\"tight_layout : falling back to Agg renderer\")\n"
     ]
    }
   ],
   "source": [
    "from plots import *\n",
    "\n",
    "def polynomial_regression():\n",
    "    \"\"\"Constructing the polynomial basis function expansion of the data,\n",
    "       and then running least squares regression.\"\"\"\n",
    "    # define parameters\n",
    "    degrees = [1, 3, 7, 12]\n",
    "    \n",
    "    # define the structure of figure\n",
    "    num_row = 2\n",
    "    num_col = 2\n",
    "    f, axs = plt.subplots(num_row, num_col)\n",
    "\n",
    "    for ind, degree in enumerate(degrees):\n",
    "        # ***************************************************\n",
    "        # INSERT YOUR CODE HERE\n",
    "        # form the data to do polynomial regression.: TODO\n",
    "        # ***************************************************\n",
    "        phi = build_poly(x, degree)\n",
    "        \n",
    "        # ***************************************************\n",
    "        # INSERT YOUR CODE HERE\n",
    "        # least square and calculate rmse: TODO\n",
    "        # ***************************************************\n",
    "        weight, L = least_squares(y, phi)\n",
    "        rmse = np.sqrt(2*L)\n",
    "        \n",
    "        \n",
    "        print(\"Processing {i}th experiment, degree={d}, rmse={loss}\".format(\n",
    "              i=ind + 1, d=degree, loss=rmse))\n",
    "        # plot fit\n",
    "        plot_fitted_curve(\n",
    "            y, x, weight, degree, axs[ind // num_col][ind % num_col])\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"visualize_polynomial_regression\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "polynomial_regression()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The fit gets not nesserarily better as we increase the degree. Because of the overfit ! The best view is the polynomial degree 7 in this case. \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Evaluating model predication performance\n",
    "\n",
    "Let us show the train and test splits for various polynomial degrees. First of all, please fill in the function `split_data()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def split_data(x, y, ratio, seed=1):\n",
    "    \"\"\"split the dataset based on the split ratio.\"\"\"\n",
    "    # set seed\n",
    "    np.random.seed(seed)\n",
    "    # ***************************************************\n",
    "    # INSERT YOUR CODE HERE\n",
    "    # split the data based on the given ratio: TODO\n",
    "    # ***************************************************\n",
    "    \n",
    "    shuffle_indices = np.random.permutation(np.arange(len(x)))\n",
    "    shuffled_y = y[shuffle_indices]\n",
    "    shuffled_x = x[shuffle_indices]\n",
    "    \n",
    "    max_i = len(x)-1\n",
    "    cut_i = np.floor(max_i * ratio)\n",
    "    \n",
    "    return shuffled_x[0:cut_i], shuffled_y[0:cut_i],shuffled_x[cut_i:max_i],shuffled_y[cut_i:max_i] \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, test your `split_data` function below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "proportion=0.9, degree=1, Training RMSE=0.497, Testing RMSE=0.198\n",
      "proportion=0.9, degree=3, Training RMSE=0.257, Testing RMSE=0.301\n",
      "proportion=0.9, degree=7, Training RMSE=0.244, Testing RMSE=0.335\n",
      "proportion=0.9, degree=12, Training RMSE=9.655, Testing RMSE=2.111\n",
      "proportion=0.5, degree=1, Training RMSE=0.464, Testing RMSE=0.526\n",
      "proportion=0.5, degree=3, Training RMSE=0.235, Testing RMSE=0.306\n",
      "proportion=0.5, degree=7, Training RMSE=0.231, Testing RMSE=0.295\n",
      "proportion=0.5, degree=12, Training RMSE=0.249, Testing RMSE=1.590\n",
      "proportion=0.1, degree=1, Training RMSE=0.476, Testing RMSE=0.545\n",
      "proportion=0.1, degree=3, Training RMSE=0.000, Testing RMSE=1.411\n",
      "proportion=0.1, degree=7, Training RMSE=8.923, Testing RMSE=8.122\n",
      "proportion=0.1, degree=12, Training RMSE=6.825, Testing RMSE=30.555\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:17: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n"
     ]
    }
   ],
   "source": [
    "def train_test_split_demo(x, y, degree, ratio, seed):\n",
    "    \"\"\"polynomial regression with different split ratios and different degrees.\"\"\"\n",
    "    # ***************************************************\n",
    "    # INSERT YOUR CODE HERE\n",
    "    # split the data, and return train and test data: TODO\n",
    "    # ***************************************************\n",
    "    x_train, y_train, x_test, y_test = split_data(x, y, ratio, seed=seed)\n",
    "    \n",
    "    # ***************************************************\n",
    "    # INSERT YOUR CODE HERE\n",
    "    # form train and test data with polynomial basis function: TODO\n",
    "    # ***************************************************\n",
    "    phi_train = build_poly(x_train, degree)\n",
    "    phi_test = build_poly(x_test, degree)\n",
    "        \n",
    "    # ***************************************************\n",
    "    # INSERT YOUR CODE HERE\n",
    "    # calcualte weight through least square.: TODO\n",
    "    # ***************************************************\n",
    "    w, L_train = least_squares(y_train, phi_train)\n",
    "    \n",
    "   \n",
    "    # ***************************************************\n",
    "    # INSERT YOUR CODE HERE\n",
    "    # calculate RMSE for train and test data,\n",
    "    # and store them in rmse_tr and rmse_te respectively: TODO\n",
    "    # ***************************************************\n",
    "    rmse_tr = np.sqrt(2*L_train)\n",
    "    rmse_te = compute_rmse(y_test, phi_test, w)\n",
    "    \n",
    "    \n",
    "    \n",
    "    print(\"proportion={p}, degree={d}, Training RMSE={tr:.3f}, Testing RMSE={te:.3f}\".format(\n",
    "          p=ratio, d=degree, tr=rmse_tr, te=rmse_te))\n",
    "\n",
    "    \n",
    "    \n",
    "seed = 6\n",
    "degrees = [1, 3, 7, 12]\n",
    "split_ratios = [0.9, 0.5, 0.1]\n",
    "\n",
    "for split_ratio in split_ratios:\n",
    "    for degree in degrees:\n",
    "        train_test_split_demo(x, y, degree, split_ratio, seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ridge Regression\n",
    "Please fill in the function below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ridge_regression(y, tx, lamb):\n",
    "    \"\"\"implement ridge regression.\"\"\"\n",
    "    # ***************************************************\n",
    "    # INSERT YOUR CODE HERE\n",
    "    # ridge regression: TODO\n",
    "    # ***************************************************\n",
    "    y = y.reshape(-1, 1)\n",
    "\n",
    "    txt = np.transpose(tx)\n",
    "    \n",
    "    XTXL = txt.dot(tx)+ lamb*np.identity(tx.shape[1])    \n",
    "  \n",
    "    w = np.linalg.inv(XTXL).dot(txt).dot(y)\n",
    "    \n",
    "    return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:17: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.23129932619129631, 0.23138563143518254, 0.23148899292308944, 0.23164509473437278, 0.2320107923344969, 0.2326636543924851, 0.23393437970084952, 0.23862040398854778, 0.2562341212666181, 0.29715886965537514]\n",
      "\n",
      "\n",
      "[0.29532541734832379, 0.295521717604384, 0.29558677978472225, 0.29536054630173997, 0.29470625899300151, 0.29247351616861589, 0.28625274508343024, 0.27697072337898615, 0.28026166047393702, 0.31963995696968167]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYEAAAEECAYAAADOJIhPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nwMwsxxwCZmY55hAwM8sxh4CZWY79f0knJPP2gzcUAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fdcbbf2aeb8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def ridge_regression_demo(x, y, degree, ratio, seed):\n",
    "    \"\"\"ridge regression demo.\"\"\"\n",
    "    # define parameter\n",
    "    lambdas = np.logspace(-3, 1, 10)    \n",
    "    # ***************************************************\n",
    "    # INSERT YOUR CODE HERE\n",
    "    # split the data, and return train and test data: TODO\n",
    "    # ***************************************************\n",
    "    x_train, y_train, x_test, y_test = split_data(x, y, ratio, seed=seed)\n",
    "    \n",
    "    # ***************************************************\n",
    "    # INSERT YOUR CODE HERE\n",
    "    # form train and test data with polynomial basis function: TODO\n",
    "    # ***************************************************\n",
    "    phi_train = build_poly(x_train, degree)\n",
    "    phi_test = build_poly(x_test, degree)\n",
    "    \n",
    "    # ***************************************************\n",
    "    # INSERT YOUR CODE HERE\n",
    "    # ridge regression with different lambda: TODO\n",
    "    # ***************************************************\n",
    "    rmse_trs = []\n",
    "    rmse_tes = []\n",
    "    \n",
    "    for lamb in lambdas:\n",
    "        \n",
    "        w = ridge_regression(y_train, phi_train, lamb)\n",
    "        rmse_trs.append(compute_rmse(y_train, phi_train, w))\n",
    "        rmse_tes.append(compute_rmse(y_test, phi_test, w))\n",
    "        \n",
    "    \n",
    "    \n",
    "    print(rmse_trs)\n",
    "    print(\"\\n\")\n",
    "    print(rmse_tes)\n",
    "    \n",
    "    plt.plot(lambdas, rmse_trs, 'b*', lambdas, rmse_tes, 'r*')\n",
    "    #plt.axis([-1000, 10, 0.2, 0.45])\n",
    "    plt.xscale('log', nonposy='clip')\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "    \n",
    "seed = 6\n",
    "degree = 7\n",
    "split_ratio = 0.5\n",
    "\n",
    "ridge_regression_demo(x, y, degree, split_ratio, seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
